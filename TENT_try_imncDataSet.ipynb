{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7173890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "from torch.optim import SGD\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.utils.data as torchdata\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# from train_model import train_model\n",
    "# from test_model import test_model\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from data import ImageNetCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84cbedf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d1710f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f9de1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUGGING: lengh of default self.samples = 50000\n",
      "DEBUGGING: lengh of second corruption samples = 0\n",
      "DEBUGGING: the root of the imagefolder class is: /local/rcs/ll3504/datasets/imagenetc/snow/1\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "weather = ['snow', 'fog', 'spatter']\n",
    "imagebase = '/local/rcs/ll3504/datasets/'\n",
    "dataset_name = 'imagenetc'\n",
    "tr_dataset = ImageNetCDataset(imagebase + dataset_name, weather, 1, transform=data_transforms['train'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "061e99cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torchdata.DataLoader(tr_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0de02c72",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29677/4006441096.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_sampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tent/data.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcor_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcor_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcor_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcor_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e7729e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28898/34970849.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Doing nothing lol\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     image, label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tent/data.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# I copied these from the ImageFolder source code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcor_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;31m# TODO: QUESTION: what is path?? a path string? Can I modify this?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUGGING: printing the path:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for image, label in train_loader:\n",
    "    print(\"Doing nothing lol\")\n",
    "#     image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093c05f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc51e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a3d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6597a299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd26fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path='/database', dataset_name='caltech-256-common'):\n",
    "    # No holdout testing data. train and test data are the same, but different transformation\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }\n",
    "\n",
    "v    te_dataset = datasets.ImageFolder(path + dataset_name + '/', data_transforms['test'])\n",
    "\n",
    "    return tr_dataset, te_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a8a1d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(train_dataset, test_dataset, valid_size=0.02, batch_size=128, train_size = 128):\n",
    "    '''\n",
    "    This function splits dataset into train, val, and test sets, and return train, val, test dataloaders.\n",
    "    Val and Test loaders are the same\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # what does the len function gives?\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "#     print(\"DEBUGGING: split =\", split)\n",
    "    random.shuffle(indices)\n",
    "    train_idx, valid_idx = indices[split:split+train_size], indices[:split]\n",
    "#     print(\"DEBUGGING: data size = \", len(train_idx), len(valid_idx))\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    \n",
    "    # print(\"DEBUGGING: the train_ind are:\", len(train_idx))\n",
    "\n",
    "\n",
    "    train_loader = torchdata.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=48, pin_memory=True, drop_last=False, sampler = train_sampler)\n",
    "    test_loader = torchdata.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=48, pin_memory=True, drop_last=False, sampler = valid_sampler)\n",
    "    dataloaders = {'train': train_loader,\n",
    "                   'val': test_loader,\n",
    "                   'test': test_loader}\n",
    "    dataset_sizes ={'train': train_size, #int(np.floor((1-valid_size) * num_train)),\n",
    "                    'val': int(np.floor(valid_size * num_train)),\n",
    "                    'test': int(np.floor(valid_size * num_train))}\n",
    "    return dataloaders, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d70b1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagebase = '/local/rcs/ll3504/datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53218aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corruption = ['fog', 'snow', 'spatter', 'gaussian_blur', 'gaussian_noise', 'brightness']\n",
    "weather = ['fog', 'snow', 'spatter', 'frost']\n",
    "digital = ['gaussian_blur', 'brightness', 'defocus_blur', 'contrast'] # NO gaussian noise in the files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cca57975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imagenetc(imagebase, batch_size=128, sample_size = 128, corruption=corruption):\n",
    "    '''\n",
    "    Returns:\n",
    "        ref_dataloaders:          ImageNet original validation data, as a reference\n",
    "        ref_dataset_sizes:        1000, not the sizes of the real dataset in the ref_loader, probs used downstream\n",
    "        corrupted_dataloaders:    A list of corrupted dataloaders, each element in a list represetns the data loaders\n",
    "                                  for one corruption type. Each element contains ['train']['val']['test'] loaders\n",
    "        corrupted_dataset_sizes:  A list of dictionaries of the sizes of each loaders for each corruption\n",
    "        corruption:               A list of corruption names, in the same order of the corrupted_dataloaders\n",
    "    '''\n",
    "    corrupted_dataloaders = {}\n",
    "    \n",
    "    imagenet_val = datasets.ImageNet(imagebase+'imagenetc/', split='val', transform=transforms.Compose([\n",
    "            transforms.Resize([224, 224]),\n",
    "            transforms.CenterCrop((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "                                   target_transform=None)#, download=False)\n",
    "    \n",
    "    random_indices = random.sample(range(0, len(imagenet_val)), int(len(imagenet_val)*0.02))\n",
    "    imagenet_val_subset = data.Subset(imagenet_val, random_indices)\n",
    "    clean_val_loader = torch.utils.data.DataLoader(imagenet_val_subset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=48)\n",
    "#     ref_dataloaders = { 'val': val_loader,\n",
    "#                        'test': val_loader}\n",
    "#     ref_dataset_sizes ={'val': int(len(val_loader.dataset)),\n",
    "#                         'test': int(len(val_loader.dataset))}\n",
    "    \n",
    "    # for every type of corruption, go to the specified severity folder\n",
    "    for corr in corruption:\n",
    "        dataloader_all_sev = []\n",
    "\n",
    "        for severity in range(1,6):\n",
    "            \n",
    "            dataset_name = 'imagenetc/' + corr + '/' + str(severity)\n",
    "            # Get dataset from folder\n",
    "            corr_trian_images, corr_test_images = get_dataset(imagebase, dataset_name)\n",
    "\n",
    "            # Get corruption-specific train, val, test loader\n",
    "                # train: training data, non-overlap with val/test\n",
    "                # val: non-overlap with train, same as test\n",
    "                # test: non-overlap with train, same as test\n",
    "\n",
    "            corr_dataloaders, _ = split_dataset(corr_trian_images, corr_test_images, valid_size=0.02, batch_size=batch_size, train_size=sample_size)\n",
    "\n",
    "            dataloader_all_sev.append(corr_dataloaders)\n",
    "            corrupted_dataloaders[corr] = dataloader_all_sev\n",
    "        \n",
    "        \n",
    "#     return ref_dataloaders, ref_dataset_sizes, corrupted_dataloaders, corrupted_dataset_sizes, corruption\n",
    "    return clean_val_loader, corrupted_dataloaders\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a18b4fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n",
      "DEBUGGING: split = 1000\n",
      "DEBUGGING: data size =  49000 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fog': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f02914603a0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f02914607c0>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f02914607c0>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f0291464be0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f02914649d0>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f02914649d0>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f0291464d90>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f0291464f40>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f0291464f40>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f0291464070>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f0291464e80>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f0291464e80>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f02914dd490>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f02914dd130>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f02914dd130>}],\n",
       " 'snow': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f02914ddeb0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f02914ddd90>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f02914ddd90>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f05a4201580>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f05a42012e0>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f05a42012e0>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f05a42019a0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f05a4201910>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f05a4201910>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f05a4201550>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f05a4201520>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f05a4201520>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f02a81dfb50>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f02a81df250>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f02a81df250>}],\n",
       " 'spatter': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f02a81df460>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f02a81df490>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f02a81df490>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f02a81dff70>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f02a81df280>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f02a81df280>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f02a35f4d60>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f02a35f4a90>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f02a35f4a90>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f02a35f4700>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f02a35f4550>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f02a35f4550>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f02a35f49d0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f02a35f4640>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f02a35f4640>}],\n",
       " 'frost': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f02aa152cd0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f02aa152640>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f02aa152640>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f02aa152fd0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f02aa1524f0>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f02aa1524f0>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f02aa1520d0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f02aa1526d0>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f02aa1526d0>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f02914a4cd0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f02914a42e0>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f02914a42e0>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f02914a4490>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f02914a4370>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f02914a4370>}],\n",
       " 'gaussian_blur': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f02914a48e0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f02914a4a00>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f02914a4a00>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f0b65a1b430>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f0b65a1b160>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f0b65a1b160>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f0b65a1b6d0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f0b65a1bdc0>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f0b65a1bdc0>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f0b6497e5b0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f0b6497ee50>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f0b6497ee50>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f0b6497e0d0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f0b6497e820>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f0b6497e820>}],\n",
       " 'brightness': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f0b6497ef40>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f0b6497e8e0>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f0b6497e8e0>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f0b6583f0d0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f0b6583f340>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f0b6583f340>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f0b6583fbb0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f0b6583fd60>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f0b6583fd60>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f0b6583f520>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f0b6583ffd0>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f0b6583ffd0>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f05baabdfd0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f05baabd340>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f05baabd340>}],\n",
       " 'defocus_blur': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f05baabd700>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f05baabd520>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f05baabd520>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f05baabd550>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f05baabda30>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f05baabda30>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f0b64d53190>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f0b64d531c0>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f0b64d531c0>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f05baa776d0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f05baa77730>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f05baa77730>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f05baa77f70>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f05baa77910>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f05baa77910>}],\n",
       " 'contrast': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f05baa778b0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f05baa77eb0>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f05baa77eb0>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f05bec18fa0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f05bec18e20>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f05bec18e20>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f0928557e80>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f0928557190>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f0928557190>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f0928557a00>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f09285575b0>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f09285575b0>},\n",
       "  {'train': <torch.utils.data.dataloader.DataLoader at 0x7f09285570d0>,\n",
       "   'val': <torch.utils.data.dataloader.DataLoader at 0x7f0928557220>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x7f0928557220>}]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_loader, imc_loaders = get_imagenetc(imagebase, batch_size=64, sample_size = 49000, corruption=(weather+digital))\n",
    "imc_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af47dfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f05baa2d700>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce0234d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imagenet(imagebase, batch_size=128, sample_size = 128):\n",
    "    # this is the imageNet validation data\n",
    "    imagenet_val = datasets.ImageNet(imagebase+'imagenetc/', split='val', transform=transforms.Compose([\n",
    "#             transforms.Resize([224, 224]),\n",
    "#             transforms.CenterCrop((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "                                   target_transform=None)#, download=False)\n",
    "    \n",
    "    # TODO: subsample some size of ImageNet training data as source\n",
    "        # Doesn't need this step\n",
    "#     print(\"DEBUGGING: imagenet_val size is:\", len(imagenet_val))\n",
    "    \n",
    "    random_indices = random.sample(range(0, len(imagenet_val)), int(len(imagenet_val)*0.02))\n",
    "#     print(\"DEBUGGING: random indices are:\", len(random_indices))\n",
    "    imagenet_val_subset = data.Subset(imagenet_val, random_indices)\n",
    "    val_loader = torch.utils.data.DataLoader(imagenet_val_subset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=48)\n",
    "    ref_dataloaders = { 'val': val_loader,\n",
    "                       'test': val_loader}\n",
    "    ref_dataset_sizes ={'val': int(len(val_loader.dataset)),\n",
    "                        'test': int(len(val_loader.dataset))}\n",
    "    \n",
    "    return ref_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c5edb380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_evaluate(corrupt_loaders, corrutpion, severity, lr):\n",
    "    start = time.time()\n",
    "    resnet50 = models.resnet50(pretrained=True)\n",
    "    resnet50 = tent.configure_model(resnet50)\n",
    "    params, param_names = tent.collect_params(resnet50)\n",
    "    optimizer = SGD(params, lr=lr)\n",
    "    tented_resnet50 = tent.Tent(resnet50, optimizer).to(device)\n",
    "\n",
    "    num_correct, num_samples = 0., 0.\n",
    "    \n",
    "    trainloader = corrupt_loaders[corrutpion][severity-1]['train']\n",
    "\n",
    "    for images, targets in trainloader:\n",
    "        logits = tented_resnet50(images.to(device))\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        num_correct += (predictions.detach().cpu() == targets).float().sum()\n",
    "        num_samples += len(targets)\n",
    "\n",
    "    adapt_time = time.time() - start\n",
    "    accuracy = num_correct / num_samples\n",
    "    print(f\"Acc =: {num_correct:#5.0f}/{num_samples:#5.0f} ({100 * accuracy: .2f} %), \\\n",
    "            Error =: {100 * (1 - accuracy): .2f} %\")\n",
    "    print(f\"Adaptation time for one epoch on {num_samples} images takes {adapt_time}s\")\n",
    "    return tented_resnet50, accuracy, adapt_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e040b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_validate(model, corrupt_loaders, corruption, severity, baseline=False):\n",
    "    if baseline:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.offline_validation()\n",
    "    valloader = corrupt_loaders[corruption][severity-1]['val']\n",
    "    \n",
    "    num_correct, num_samples = 0., 0.\n",
    "\n",
    "#     with model.no_grad():\n",
    "    for images, targets in valloader:\n",
    "        logits = model(images.to(device))\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        num_correct += (predictions.detach().cpu() == targets).float().sum()\n",
    "        num_samples += len(targets)\n",
    "\n",
    "    accuracy = num_correct / num_samples\n",
    "    print(f\"Validation Acc =: {num_correct:#5.0f}/{num_samples:#5.0f} ({100 * accuracy: .2f} %), \\\n",
    "            Validation Error =: {100 * (1 - accuracy): .2f} %\")\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1650e09f",
   "metadata": {},
   "source": [
    "# Val Acc > Train?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d36d82a",
   "metadata": {},
   "source": [
    "## Is the model still updating in validation phase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23dafc53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 241, in _feed\n",
      "    close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 241, in _feed\n",
      "    close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 241, in _feed\n",
      "    close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 241, in _feed\n",
      "    close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 241, in _feed\n",
      "    close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 241, in _feed\n",
      "    close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 241, in _feed\n",
      "    close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 241, in _feed\n",
      "    close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 241, in _feed\n",
      "    close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 241, in _feed\n",
      "    close()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 241, in _feed\n",
      "    close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 241, in _feed\n",
      "    close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 241, in _feed\n",
      "    close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 241, in _feed\n",
      "    close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 241, in _feed\n",
      "    close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc =: 22852./48960. ( 46.67 %),         Validation Error =:  53.33 %\n"
     ]
    }
   ],
   "source": [
    "# turn model on offline validation mode, check if the corrupted set is adapted\n",
    "lr = 0.00025\n",
    "bs = 64\n",
    "\n",
    "# ONLINE adaptation adaptation on the \"training set\"\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet50 = tent.configure_model(resnet50)\n",
    "params, param_names = tent.collect_params(resnet50)\n",
    "optimizer = SGD(params, lr=lr)\n",
    "tented_resnet50 = tent.Tent(resnet50, optimizer).to(device)\n",
    "\n",
    "tented_resnet50.offline_validation()\n",
    "valloader = imc_loaders['fog'][2]['train']\n",
    "\n",
    "num_correct, num_samples = 0., 0.\n",
    "\n",
    "# tented_resnet50.model.eval()\n",
    "#     with model.no_grad():\n",
    "for images, targets in valloader:\n",
    "    logits = tented_resnet50(images.to(device))\n",
    "    predictions = logits.argmax(dim=1)\n",
    "    num_correct += (predictions.detach().cpu() == targets).float().sum()\n",
    "    num_samples += len(targets)\n",
    "\n",
    "accuracy = num_correct / num_samples\n",
    "print(f\"Validation Acc =: {num_correct:#5.0f}/{num_samples:#5.0f} ({100 * accuracy: .2f} %), \\\n",
    "        Validation Error =: {100 * (1 - accuracy): .2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7fdc327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valloader = imc_loaders['fog'][2]['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60b2e5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc =: 22841./49000. ( 46.61 %),         Validation Error =:  53.39 %\n"
     ]
    }
   ],
   "source": [
    "# evaluate on the corrupted set on baseline resnet50 model, the result should be comparable same as above cell\n",
    "num_correct, num_samples = 0., 0.\n",
    "\n",
    "baseline = models.resnet50(pretrained=True).to(device)\n",
    "baseline.eval()\n",
    "for images, targets in valloader:\n",
    "    logits = baseline(images.to(device))\n",
    "    predictions = logits.argmax(dim=1)\n",
    "    num_correct += (predictions.detach().cpu() == targets).float().sum()\n",
    "    num_samples += len(targets)\n",
    "\n",
    "accuracy = num_correct / num_samples\n",
    "print(f\"Validation Acc =: {num_correct:#5.0f}/{num_samples:#5.0f} ({100 * accuracy: .2f} %), \\\n",
    "        Validation Error =: {100 * (1 - accuracy): .2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6a3b64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc =:  759./1000. ( 75.90 %),         Validation Error =:  24.10 %\n"
     ]
    }
   ],
   "source": [
    "# evaluate on the clean on baseline resnet50 model, the result should be a lot better than above cell\n",
    "num_correct, num_samples = 0., 0.\n",
    "\n",
    "baseline = models.resnet50(pretrained=True).to(device)\n",
    "baseline.eval()\n",
    "for images, targets in clean_loader:\n",
    "    logits = baseline(images.to(device))\n",
    "    predictions = logits.argmax(dim=1)\n",
    "    num_correct += (predictions.detach().cpu() == targets).float().sum()\n",
    "    num_samples += len(targets)\n",
    "\n",
    "accuracy = num_correct / num_samples\n",
    "print(f\"Validation Acc =: {num_correct:#5.0f}/{num_samples:#5.0f} ({100 * accuracy: .2f} %), \\\n",
    "        Validation Error =: {100 * (1 - accuracy): .2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6b2be6",
   "metadata": {},
   "source": [
    "## Check if my offline_validate function is correctly implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3729956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_validate_train(model, corrupt_loaders, corruption, severity, baseline=False):\n",
    "    if baseline:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.offline_validation()\n",
    "    valloader = corrupt_loaders[corruption][severity-1]['train']\n",
    "    \n",
    "    num_correct, num_samples = 0., 0.\n",
    "\n",
    "#     with model.no_grad():\n",
    "    for images, targets in valloader:\n",
    "        logits = model(images.to(device))\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        num_correct += (predictions.detach().cpu() == targets).float().sum()\n",
    "        num_samples += len(targets)\n",
    "\n",
    "    accuracy = num_correct / num_samples\n",
    "    print(f\"Validation Acc on Train =: {num_correct:#5.0f}/{num_samples:#5.0f} ({100 * accuracy: .2f} %), \\\n",
    "            Validation Error =: {100 * (1 - accuracy): .2f} %\")\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b70efd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corruption: fog, Severity: 1\n",
      "Validation Acc on Train =: 30251./48960. ( 61.79 %),             Validation Error =:  38.21 %\n",
      "Validation Acc =:  612./ 960. ( 63.75 %),             Validation Error =:  36.25 %\n",
      "Corruption: fog, Severity: 2\n",
      "Validation Acc on Train =: 27364./48960. ( 55.89 %),             Validation Error =:  44.11 %\n",
      "Validation Acc =:  539./ 960. ( 56.15 %),             Validation Error =:  43.85 %\n",
      "Corruption: fog, Severity: 3\n",
      "Validation Acc on Train =: 22855./48960. ( 46.68 %),             Validation Error =:  53.32 %\n",
      "Validation Acc =:  426./ 960. ( 44.38 %),             Validation Error =:  55.62 %\n",
      "Corruption: fog, Severity: 4\n",
      "Validation Acc on Train =: 19800./48960. ( 40.44 %),             Validation Error =:  59.56 %\n",
      "Validation Acc =:  371./ 960. ( 38.65 %),             Validation Error =:  61.35 %\n",
      "Corruption: fog, Severity: 5\n",
      "Validation Acc on Train =: 11955./48960. ( 24.42 %),             Validation Error =:  75.58 %\n",
      "Validation Acc =:  241./ 960. ( 25.10 %),             Validation Error =:  74.90 %\n",
      "Averag online accuracy for fog:  45.84 %,             Averag online error for fog:  54.16 % \n",
      "\n",
      "Averag validation accuracy for fog:  45.60 %,             Averag validation error for fog:  54.40 % \n",
      "======================================================================================\n",
      "Corruption: snow, Severity: 1\n",
      "Validation Acc on Train =: 26698./48960. ( 54.53 %),             Validation Error =:  45.47 %\n",
      "Validation Acc =:  544./ 960. ( 56.67 %),             Validation Error =:  43.33 %\n",
      "Corruption: snow, Severity: 2\n",
      "Validation Acc on Train =: 15667./48960. ( 32.00 %),             Validation Error =:  68.00 %\n",
      "Validation Acc =:  286./ 960. ( 29.79 %),             Validation Error =:  70.21 %\n",
      "Corruption: snow, Severity: 3\n",
      "Validation Acc on Train =: 17231./48960. ( 35.19 %),             Validation Error =:  64.81 %\n",
      "Validation Acc =:  341./ 960. ( 35.52 %),             Validation Error =:  64.48 %\n",
      "Corruption: snow, Severity: 4\n",
      "Validation Acc on Train =: 11773./48960. ( 24.05 %),             Validation Error =:  75.95 %\n",
      "Validation Acc =:  233./ 960. ( 24.27 %),             Validation Error =:  75.73 %\n",
      "Corruption: snow, Severity: 5\n",
      "Validation Acc on Train =: 8274./48960. ( 16.90 %),             Validation Error =:  83.10 %\n",
      "Validation Acc =:  161./ 960. ( 16.77 %),             Validation Error =:  83.23 %\n",
      "Averag online accuracy for snow:  32.53 %,             Averag online error for snow:  67.47 % \n",
      "\n",
      "Averag validation accuracy for snow:  32.60 %,             Averag validation error for snow:  67.40 % \n",
      "======================================================================================\n",
      "Corruption: spatter, Severity: 1\n",
      "Validation Acc on Train =: 35169./48960. ( 71.83 %),             Validation Error =:  28.17 %\n",
      "Validation Acc =:  689./ 960. ( 71.77 %),             Validation Error =:  28.23 %\n",
      "Corruption: spatter, Severity: 2\n",
      "Validation Acc on Train =: 29672./48960. ( 60.60 %),             Validation Error =:  39.40 %\n",
      "Validation Acc =:  574./ 960. ( 59.79 %),             Validation Error =:  40.21 %\n",
      "Corruption: spatter, Severity: 3\n",
      "Validation Acc on Train =: 24212./48960. ( 49.45 %),             Validation Error =:  50.55 %\n",
      "Validation Acc =:  468./ 960. ( 48.75 %),             Validation Error =:  51.25 %\n",
      "Corruption: spatter, Severity: 4\n",
      "Validation Acc on Train =: 18718./48960. ( 38.23 %),             Validation Error =:  61.77 %\n",
      "Validation Acc =:  375./ 960. ( 39.06 %),             Validation Error =:  60.94 %\n",
      "Corruption: spatter, Severity: 5\n",
      "Validation Acc on Train =: 12582./48960. ( 25.70 %),             Validation Error =:  74.30 %\n",
      "Validation Acc =:  246./ 960. ( 25.62 %),             Validation Error =:  74.38 %\n",
      "Averag online accuracy for spatter:  49.16 %,             Averag online error for spatter:  50.84 % \n",
      "\n",
      "Averag validation accuracy for spatter:  49.00 %,             Averag validation error for spatter:  51.00 % \n",
      "======================================================================================\n",
      "Corruption: frost, Severity: 1\n",
      "Validation Acc on Train =: 30001./48960. ( 61.28 %),             Validation Error =:  38.72 %\n",
      "Validation Acc =:  586./ 960. ( 61.04 %),             Validation Error =:  38.96 %\n",
      "Corruption: frost, Severity: 2\n",
      "Validation Acc on Train =: 21593./48960. ( 44.10 %),             Validation Error =:  55.90 %\n",
      "Validation Acc =:  432./ 960. ( 45.00 %),             Validation Error =:  55.00 %\n",
      "Corruption: frost, Severity: 3\n",
      "Validation Acc on Train =: 15716./48960. ( 32.10 %),             Validation Error =:  67.90 %\n",
      "Validation Acc =:  322./ 960. ( 33.54 %),             Validation Error =:  66.46 %\n",
      "Corruption: frost, Severity: 4\n",
      "Validation Acc on Train =: 14660./48960. ( 29.94 %),             Validation Error =:  70.06 %\n",
      "Validation Acc =:  261./ 960. ( 27.19 %),             Validation Error =:  72.81 %\n",
      "Corruption: frost, Severity: 5\n",
      "Validation Acc on Train =: 11392./48960. ( 23.27 %),             Validation Error =:  76.73 %\n",
      "Validation Acc =:  244./ 960. ( 25.42 %),             Validation Error =:  74.58 %\n",
      "Averag online accuracy for frost:  38.14 %,             Averag online error for frost:  61.86 % \n",
      "\n",
      "Averag validation accuracy for frost:  38.44 %,             Averag validation error for frost:  61.56 % \n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Debug the offline_validate function, running on the training & validation data\n",
    "# expect similar performance on both set\n",
    "lr = 0.00025\n",
    "bs = 64\n",
    "\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet50 = tent.configure_model(resnet50)\n",
    "params, param_names = tent.collect_params(resnet50)\n",
    "optimizer = SGD(params, lr=lr)\n",
    "tented_resnet50 = tent.Tent(resnet50, optimizer).to(device)\n",
    "\n",
    "for corr in weather:\n",
    "    online_acc_sum = 0\n",
    "    validate_acc_sum = 0\n",
    "\n",
    "    for severity in range(1,6):\n",
    "        print(f\"Corruption: {corr}, Severity: {severity}\")\n",
    "        \n",
    "        # online adaptation:\n",
    "#         start = time.time()\n",
    "        accuracy = offline_validate_train(tented_resnet50, imc_loaders, corr, severity)\n",
    "#         adapt_time = time.time() - start\n",
    "        online_acc_sum += accuracy\n",
    "        \n",
    "        # offline validation:\n",
    "        val_acc = offline_validate(tented_resnet50, imc_loaders, corr, severity)\n",
    "        validate_acc_sum += val_acc\n",
    "        \n",
    "    print(f\"Averag online accuracy for {corr}: {100 * (online_acc_sum / 5): .2f} %, \\\n",
    "            Averag online error for {corr}: {100 * (1 - online_acc_sum / 5): .2f} % \")\n",
    "    print()\n",
    "    print(f\"Averag validation accuracy for {corr}: {100 * (validate_acc_sum / 5): .2f} %, \\\n",
    "            Averag validation error for {corr}: {100 * (1 - validate_acc_sum / 5): .2f} % \")\n",
    "    print(\"======================================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ee7e8",
   "metadata": {},
   "source": [
    "# Replicate TENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db08fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corruption: fog, Severity: 1\n",
      "Acc =: 33750./48960. ( 68.93 %),             Error =:  31.07 %\n",
      "Adaptation time for one epoch on 48960.0 images takes 136.8747386932373s\n",
      "Validation Acc =:  656./ 960. ( 68.33 %),             Validation Error =:  31.67 %\n",
      "Corruption: fog, Severity: 2\n",
      "Acc =: 32625./48960. ( 66.64 %),             Error =:  33.36 %\n",
      "Adaptation time for one epoch on 48960.0 images takes 134.08197832107544s\n",
      "Validation Acc =:  667./ 960. ( 69.48 %),             Validation Error =:  30.52 %\n",
      "Corruption: fog, Severity: 3\n",
      "Acc =: 30818./48960. ( 62.95 %),             Error =:  37.05 %\n",
      "Adaptation time for one epoch on 48960.0 images takes 132.2472791671753s\n",
      "Validation Acc =:  594./ 960. ( 61.87 %),             Validation Error =:  38.13 %\n",
      "Corruption: fog, Severity: 4\n",
      "Acc =: 29473./48960. ( 60.20 %),             Error =:  39.80 %\n",
      "Adaptation time for one epoch on 48960.0 images takes 133.57329559326172s\n",
      "Validation Acc =:  605./ 960. ( 63.02 %),             Validation Error =:  36.98 %\n",
      "Corruption: fog, Severity: 5\n",
      "Acc =: 25398./48960. ( 51.88 %),             Error =:  48.12 %\n",
      "Adaptation time for one epoch on 48960.0 images takes 132.8651785850525s\n",
      "Validation Acc =:  534./ 960. ( 55.62 %),             Validation Error =:  44.38 %\n",
      "Averag online accuracy for fog:  62.12 %,             Averag online error for fog:  37.88 % \n",
      "\n",
      "Averag validation accuracy for fog:  63.67 %,             Averag validation error for fog:  36.33 % \n",
      "======================================================================================\n",
      "Corruption: snow, Severity: 1\n",
      "Acc =: 30368./48960. ( 62.03 %),             Error =:  37.97 %\n",
      "Adaptation time for one epoch on 48960.0 images takes 133.90230298042297s\n",
      "Validation Acc =:  606./ 960. ( 63.13 %),             Validation Error =:  36.87 %\n",
      "Corruption: snow, Severity: 2\n",
      "Acc =: 24076./48960. ( 49.17 %),             Error =:  50.83 %\n",
      "Adaptation time for one epoch on 48960.0 images takes 132.92508816719055s\n",
      "Validation Acc =:  492./ 960. ( 51.25 %),             Validation Error =:  48.75 %\n",
      "Corruption: snow, Severity: 3\n",
      "Acc =: 24499./48960. ( 50.04 %),             Error =:  49.96 %\n",
      "Adaptation time for one epoch on 48960.0 images takes 133.38211512565613s\n",
      "Validation Acc =:  504./ 960. ( 52.50 %),             Validation Error =:  47.50 %\n",
      "Corruption: snow, Severity: 4\n",
      "Acc =: 20033./48960. ( 40.92 %),             Error =:  59.08 %\n",
      "Adaptation time for one epoch on 48960.0 images takes 132.5709195137024s\n",
      "Validation Acc =:  421./ 960. ( 43.85 %),             Validation Error =:  56.15 %\n",
      "Corruption: snow, Severity: 5\n",
      "Acc =: 18783./48960. ( 38.36 %),             Error =:  61.64 %\n",
      "Adaptation time for one epoch on 48960.0 images takes 132.84592509269714s\n",
      "Validation Acc =:  392./ 960. ( 40.83 %),             Validation Error =:  59.17 %\n",
      "Averag online accuracy for snow:  48.10 %,             Averag online error for snow:  51.90 % \n",
      "\n",
      "Averag validation accuracy for snow:  50.31 %,             Averag validation error for snow:  49.69 % \n",
      "======================================================================================\n",
      "Corruption: spatter, Severity: 1\n",
      "Acc =: 35637./48960. ( 72.79 %),             Error =:  27.21 %\n",
      "Adaptation time for one epoch on 48960.0 images takes 132.65840077400208s\n",
      "Validation Acc =:  695./ 960. ( 72.40 %),             Validation Error =:  27.60 %\n",
      "Corruption: spatter, Severity: 2\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00025\n",
    "bs = 64\n",
    "\n",
    "# ONLINE adaptation adaptation on the \"training set\"\n",
    "\n",
    "for corr in weather:\n",
    "    online_acc_sum = 0\n",
    "    validate_acc_sum = 0\n",
    "\n",
    "    for severity in range(1,6):\n",
    "        print(f\"Corruption: {corr}, Severity: {severity}\")\n",
    "        \n",
    "        # online adaptation:\n",
    "        start = time.time()\n",
    "        adapted_model, accuracy, _ = online_evaluate(imc_loaders, corr, severity, lr)\n",
    "        adapt_time = time.time() - start\n",
    "        online_acc_sum += accuracy\n",
    "        \n",
    "        # offline validation:\n",
    "        val_acc = offline_validate(adapted_model, imc_loaders, corr, severity)\n",
    "        validate_acc_sum += val_acc\n",
    "        \n",
    "    print(f\"Averag online accuracy for {corr}: {100 * (online_acc_sum / 5): .2f} %, \\\n",
    "            Averag online error for {corr}: {100 * (1 - online_acc_sum / 5): .2f} % \")\n",
    "    print()\n",
    "    print(f\"Averag validation accuracy for {corr}: {100 * (validate_acc_sum / 5): .2f} %, \\\n",
    "            Averag validation error for {corr}: {100 * (1 - validate_acc_sum / 5): .2f} % \")\n",
    "    print(\"======================================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9282bc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70216f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "737174ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fog', 'snow', 'spatter', 'gaussian_blur', 'brightness']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_us = ['fog', 'snow', 'spatter']\n",
    "digital_us = ['gaussian_blur', 'brightness']\n",
    "weather_us + digital_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cbb255d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corruption: fog, Severity: 3\n",
      "Acc =: 30820./48960. ( 62.95 %),             Error =:  37.05 %\n",
      "Adaptation time for one epoch on 48960.0 images takes 132.4763262271881s\n",
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  607./ 960. ( 63.23 %),             Validation Error =:  36.77 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  439./ 960. ( 45.73 %),             Validation Error =:  54.27 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  566./ 960. ( 58.96 %),             Validation Error =:  41.04 %\n",
      "cross-validating on corruption = gaussian_blur\n",
      "Validation Acc =:  436./ 960. ( 45.42 %),             Validation Error =:  54.58 %\n",
      "cross-validating on corruption = brightness\n",
      "Validation Acc =:  675./ 960. ( 70.31 %),             Validation Error =:  29.69 %\n",
      "======================================================================================\n",
      "Corruption: snow, Severity: 3\n",
      "Acc =: 24388./48960. ( 49.81 %),             Error =:  50.19 %\n",
      "Adaptation time for one epoch on 48960.0 images takes 133.70379257202148s\n",
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  575./ 960. ( 59.90 %),             Validation Error =:  40.10 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  477./ 960. ( 49.69 %),             Validation Error =:  50.31 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  566./ 960. ( 58.96 %),             Validation Error =:  41.04 %\n",
      "cross-validating on corruption = gaussian_blur\n",
      "Validation Acc =:  426./ 960. ( 44.38 %),             Validation Error =:  55.62 %\n",
      "cross-validating on corruption = brightness\n",
      "Validation Acc =:  690./ 960. ( 71.88 %),             Validation Error =:  28.12 %\n",
      "======================================================================================\n",
      "Corruption: spatter, Severity: 3\n",
      "Acc =: 29645./48960. ( 60.55 %),             Error =:  39.45 %\n",
      "Adaptation time for one epoch on 48960.0 images takes 134.25695729255676s\n",
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  586./ 960. ( 61.04 %),             Validation Error =:  38.96 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  455./ 960. ( 47.40 %),             Validation Error =:  52.60 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  590./ 960. ( 61.46 %),             Validation Error =:  38.54 %\n",
      "cross-validating on corruption = gaussian_blur\n",
      "Validation Acc =:  415./ 960. ( 43.23 %),             Validation Error =:  56.77 %\n",
      "cross-validating on corruption = brightness\n",
      "Validation Acc =:  689./ 960. ( 71.77 %),             Validation Error =:  28.23 %\n",
      "======================================================================================\n",
      "Corruption: gaussian_blur, Severity: 3\n",
      "Acc =: 22521./48960. ( 46.00 %),             Error =:  54.00 %\n",
      "Adaptation time for one epoch on 48960.0 images takes 132.11392045021057s\n",
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  579./ 960. ( 60.31 %),             Validation Error =:  39.69 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  446./ 960. ( 46.46 %),             Validation Error =:  53.54 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  567./ 960. ( 59.06 %),             Validation Error =:  40.94 %\n",
      "cross-validating on corruption = gaussian_blur\n",
      "Validation Acc =:  478./ 960. ( 49.79 %),             Validation Error =:  50.21 %\n",
      "cross-validating on corruption = brightness\n",
      "Validation Acc =:  689./ 960. ( 71.77 %),             Validation Error =:  28.23 %\n",
      "======================================================================================\n",
      "Corruption: brightness, Severity: 3\n",
      "Acc =: 35028./48960. ( 71.54 %),             Error =:  28.46 %\n",
      "Adaptation time for one epoch on 48960.0 images takes 133.81018900871277s\n",
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  597./ 960. ( 62.19 %),             Validation Error =:  37.81 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  434./ 960. ( 45.21 %),             Validation Error =:  54.79 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  555./ 960. ( 57.81 %),             Validation Error =:  42.19 %\n",
      "cross-validating on corruption = gaussian_blur\n",
      "Validation Acc =:  408./ 960. ( 42.50 %),             Validation Error =:  57.50 %\n",
      "cross-validating on corruption = brightness\n",
      "Validation Acc =:  671./ 960. ( 69.90 %),             Validation Error =:  30.10 %\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "cross_valid_acc = {}\n",
    "\n",
    "for corr in weather_us + digital_us:\n",
    "    online_acc_sum = 0\n",
    "    cross_valid_acc[corr] = {}\n",
    "    \n",
    "    for severity in [3]:\n",
    "        print(f\"Corruption: {corr}, Severity: {severity}\")\n",
    "\n",
    "        # online adaptation:\n",
    "        adapted_model, accuracy, _ = online_evaluate(imc_loaders, corr, severity, lr)\n",
    "        online_acc_sum += accuracy\n",
    "        \n",
    "        \n",
    "        # offline validation:\n",
    "        for val_corr in weather_us + digital_us:\n",
    "            print(f\"cross-validating on corruption = {val_corr}\")\n",
    "            val_acc = offline_validate(adapted_model, imc_loaders, val_corr, severity)\n",
    "            cross_valid_acc[corr][val_corr] = val_acc\n",
    "\n",
    "#     print(f\"Averag online accuracy for {corr}: {100 * (online_acc_sum / 5): .2f} %, \\\n",
    "#             Averag online error for {corr}: {100 * (1 - online_acc_sum / 5): .2f} % \")\n",
    "#     print()\n",
    "#     print(f\"Averag validation accuracy for {corr}: {100 * (validate_acc_sum / 5): .2f} %, \\\n",
    "#             Averag validation error for {corr}: {100 * (1 - validate_acc_sum / 5): .2f} % \")\n",
    "    print(\"======================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1afde225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  446./ 960. ( 46.46 %),             Validation Error =:  53.54 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  337./ 960. ( 35.10 %),             Validation Error =:  64.90 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  485./ 960. ( 50.52 %),             Validation Error =:  49.48 %\n",
      "cross-validating on corruption = gaussian_blur\n",
      "Validation Acc =:  392./ 960. ( 40.83 %),             Validation Error =:  59.17 %\n",
      "cross-validating on corruption = brightness\n",
      "Validation Acc =:  690./ 960. ( 71.88 %),             Validation Error =:  28.12 %\n"
     ]
    }
   ],
   "source": [
    "severity = 3\n",
    "baseline_valid_acc = {}\n",
    "\n",
    "vanilla = models.resnet50(pretrained=True).to(device)\n",
    "for val_corr in weather_us + digital_us:\n",
    "    print(f\"cross-validating on corruption = {val_corr}\")\n",
    "    val_acc = offline_validate(vanilla, imc_loaders, val_corr, severity, baseline=True)\n",
    "    baseline_valid_acc[val_corr] = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8c3fbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "765"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "49000 // 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11a01507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48960"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "765 * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beaa3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
