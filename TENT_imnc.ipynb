{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a77070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.utils.data as torchdata\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# from train_model import train_model\n",
    "# from test_model import test_model\n",
    "%matplotlib inline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e14abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc016d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db45d1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american-flag\n"
     ]
    }
   ],
   "source": [
    "filePath = '/local/rcs/ll3504/datasets/256_ObjectCategories/'\n",
    "namelist = os.listdir(filePath)\n",
    "nameDic_cal = {}\n",
    "for name in namelist:\n",
    "    splits = name.split(\".\")\n",
    "    nameDic_cal[int(splits[0])-1] = splits[1]\n",
    "print(nameDic_cal[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34a208f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path='/database', dataset_name='caltech-256-common'):\n",
    "    # No holdout testing data. train and test data are the same, but different transformation\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    tr_dataset = datasets.ImageFolder(path + dataset_name + '/', data_transforms['train'])\n",
    "    te_dataset = datasets.ImageFolder(path + dataset_name + '/', data_transforms['test'])\n",
    "\n",
    "    return tr_dataset, te_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b7e4972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(train_dataset, test_dataset, valid_size=0.2, batch_size=128, train_size = 128):\n",
    "    '''\n",
    "    This function splits dataset into train, val, and test sets, and return train, val, test dataloaders.\n",
    "    Val and Test loaders are the same\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # what does the len function gives?\n",
    "    num_train = len(train_dataset)\n",
    "    # print(\"DEBUGGING: overall training data size =\", num_train)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    random.shuffle(indices)\n",
    "    train_idx, valid_idx = indices[split:split+train_size], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    \n",
    "    # print(\"DEBUGGING: the train_ind are:\", len(train_idx))\n",
    "\n",
    "\n",
    "    train_loader = torchdata.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=48, pin_memory=True, drop_last=True, sampler = train_sampler)\n",
    "    test_loader = torchdata.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=48, pin_memory=True, drop_last=True, sampler = valid_sampler)\n",
    "    dataloaders = {'train': train_loader,\n",
    "                   'val': test_loader,\n",
    "                   'test': test_loader}\n",
    "    dataset_sizes ={'train': train_size, #int(np.floor((1-valid_size) * num_train)),\n",
    "                    'val': int(np.floor(valid_size * num_train)),\n",
    "                    'test': int(np.floor(valid_size * num_train))}\n",
    "    return dataloaders, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96f86385",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagebase = '/local/rcs/ll3504/datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa15ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corruption = ['fog', 'snow', 'spatter', 'gaussian_blur', 'gaussian_noise', 'brightness']\n",
    "weather = ['fog', 'frost', 'snow', 'spatter']\n",
    "digit=['gaussian_blur', 'gaussian_noise', 'brightness']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acc8450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imagenetc(imagebase, batch_size=128, sample_size = 128, corruption=corruption):\n",
    "    '''\n",
    "    Returns:\n",
    "        ref_dataloaders:          ImageNet original validation data, as a reference\n",
    "        ref_dataset_sizes:        1000, not the sizes of the real dataset in the ref_loader, probs used downstream\n",
    "        corrupted_dataloaders:    A list of corrupted dataloaders, each element in a list represetns the data loaders\n",
    "                                  for one corruption type. Each element contains ['train']['val']['test'] loaders\n",
    "        corrupted_dataset_sizes:  A list of dictionaries of the sizes of each loaders for each corruption\n",
    "        corruption:               A list of corruption names, in the same order of the corrupted_dataloaders\n",
    "    '''\n",
    "\n",
    "    corrupted_dataloaders = {}\n",
    "    \n",
    "    # for every type of corruption, go to the specified severity folder\n",
    "    for corr in corruption:\n",
    "        dataloader_all_sev = []\n",
    "\n",
    "        for severity in range(1,6):\n",
    "            \n",
    "            dataset_name = 'imagenetc/' + corr + '/' + str(severity)\n",
    "            # Get dataset from folder\n",
    "            corr_trian_images, corr_test_images = get_dataset(imagebase, dataset_name)\n",
    "\n",
    "            # Get corruption-specific train, val, test loader\n",
    "                # train: training data, non-overlap with val/test\n",
    "                # val: non-overlap with train, same as test\n",
    "                # test: non-overlap with train, same as test\n",
    "\n",
    "            corr_dataloaders, _ = split_dataset(corr_trian_images, corr_test_images, valid_size=0.02, batch_size=batch_size, train_size=sample_size)\n",
    "\n",
    "            dataloader_all_sev.append(corr_dataloaders)\n",
    "            corrupted_dataloaders[corr] = dataloader_all_sev\n",
    "        \n",
    "        \n",
    "#     return ref_dataloaders, ref_dataset_sizes, corrupted_dataloaders, corrupted_dataset_sizes, corruption\n",
    "    return corrupted_dataloaders\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1be443f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': <torch.utils.data.dataloader.DataLoader at 0x7f37234a91c0>,\n",
       "  'val': <torch.utils.data.dataloader.DataLoader at 0x7f37234a9130>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f37234a9130>},\n",
       " {'train': <torch.utils.data.dataloader.DataLoader at 0x7f37234a9610>,\n",
       "  'val': <torch.utils.data.dataloader.DataLoader at 0x7f37234a9280>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f37234a9280>},\n",
       " {'train': <torch.utils.data.dataloader.DataLoader at 0x7f37234a9c10>,\n",
       "  'val': <torch.utils.data.dataloader.DataLoader at 0x7f37234a90d0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f37234a90d0>},\n",
       " {'train': <torch.utils.data.dataloader.DataLoader at 0x7f37045a7160>,\n",
       "  'val': <torch.utils.data.dataloader.DataLoader at 0x7f37045a71f0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f37045a71f0>},\n",
       " {'train': <torch.utils.data.dataloader.DataLoader at 0x7f37045a75e0>,\n",
       "  'val': <torch.utils.data.dataloader.DataLoader at 0x7f37045a7670>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f37045a7670>}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imc_loaders = get_imagenetc(imagebase, batch_size=64, sample_size = 49000, corruption=weather)\n",
    "imc_loaders['frost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8f41fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_evaluate(corrupt_loaders, corrutpion, severity, lr):\n",
    "    resnet50 = models.resnet50(pretrained=True)\n",
    "    resnet50 = tent.configure_model(resnet50)\n",
    "    params, param_names = tent.collect_params(resnet50)\n",
    "    optimizer = SGD(params, lr=lr)\n",
    "    tented_resnet50 = tent.Tent(resnet50, optimizer).to(device)\n",
    "\n",
    "    num_correct, num_samples = 0., 0.\n",
    "    \n",
    "    trainloader = corrupt_loaders[corrutpion][severity-1]['train']\n",
    "\n",
    "    for images, targets in trainloader:\n",
    "        logits = tented_resnet50(images.to(device))\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        num_correct += (predictions.detach().cpu() == targets).float().sum()\n",
    "        num_samples += len(targets)\n",
    "\n",
    "    accuracy = num_correct / num_samples\n",
    "    print(f\"Acc =: {num_correct:#5.0f}/{num_samples:#5.0f} ({100 * accuracy: .2f} %), \\\n",
    "            Error =: {100 * (1 - accuracy): .2f} %\")\n",
    "    \n",
    "    return tented_resnet50, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8db26ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_validate(model, corrupt_loaders, corruption, severity, baseline=False):\n",
    "    if baseline:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.offline_validation()\n",
    "    valloader = corrupt_loaders[corruption][severity-1]['val']\n",
    "    \n",
    "    num_correct, num_samples = 0., 0.\n",
    "\n",
    "#     with model.no_grad():\n",
    "    for images, targets in valloader:\n",
    "        logits = model(images.to(device))\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        num_correct += (predictions.detach().cpu() == targets).float().sum()\n",
    "        num_samples += len(targets)\n",
    "\n",
    "    accuracy = num_correct / num_samples\n",
    "    print(f\"Validation Acc =: {num_correct:#5.0f}/{num_samples:#5.0f} ({100 * accuracy: .2f} %), \\\n",
    "            Validation Error =: {100 * (1 - accuracy): .2f} %\")\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1eb4962f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corruption: fog, Severity: 1\n",
      "Acc =: 33715./48960. ( 68.86 %),             Error =:  31.14 %\n",
      "Validation Acc =:  656./ 960. ( 68.33 %),             Validation Error =:  31.67 %\n",
      "Corruption: fog, Severity: 2\n",
      "Acc =: 32627./48960. ( 66.64 %),             Error =:  33.36 %\n",
      "Validation Acc =:  601./ 960. ( 62.60 %),             Validation Error =:  37.40 %\n",
      "Corruption: fog, Severity: 3\n",
      "Acc =: 30822./48960. ( 62.95 %),             Error =:  37.05 %\n",
      "Validation Acc =:  621./ 960. ( 64.69 %),             Validation Error =:  35.31 %\n",
      "Corruption: fog, Severity: 4\n",
      "Acc =: 29398./48960. ( 60.04 %),             Error =:  39.96 %\n",
      "Validation Acc =:  592./ 960. ( 61.67 %),             Validation Error =:  38.33 %\n",
      "Corruption: fog, Severity: 5\n",
      "Acc =: 25396./48960. ( 51.87 %),             Error =:  48.13 %\n",
      "Validation Acc =:  526./ 960. ( 54.79 %),             Validation Error =:  45.21 %\n",
      "Averag online accuracy for fog:  62.07 %,             Averag online error for fog:  37.93 % \n",
      "\n",
      "Averag validation accuracy for fog:  62.42 %,             Averag validation error for fog:  37.58 % \n",
      "======================================================================================\n",
      "Corruption: frost, Severity: 1\n",
      "Acc =: 31641./48960. ( 64.63 %),             Error =:  35.37 %\n",
      "Validation Acc =:  636./ 960. ( 66.25 %),             Validation Error =:  33.75 %\n",
      "Corruption: frost, Severity: 2\n",
      "Acc =: 25819./48960. ( 52.73 %),             Error =:  47.27 %\n",
      "Validation Acc =:  504./ 960. ( 52.50 %),             Validation Error =:  47.50 %\n",
      "Corruption: frost, Severity: 3\n",
      "Acc =: 21278./48960. ( 43.46 %),             Error =:  56.54 %\n",
      "Validation Acc =:  447./ 960. ( 46.56 %),             Validation Error =:  53.44 %\n",
      "Corruption: frost, Severity: 4\n",
      "Acc =: 20618./48960. ( 42.11 %),             Error =:  57.89 %\n",
      "Validation Acc =:  419./ 960. ( 43.65 %),             Validation Error =:  56.35 %\n",
      "Corruption: frost, Severity: 5\n",
      "Acc =: 17627./48960. ( 36.00 %),             Error =:  64.00 %\n",
      "Validation Acc =:  362./ 960. ( 37.71 %),             Validation Error =:  62.29 %\n",
      "Averag online accuracy for frost:  47.79 %,             Averag online error for frost:  52.21 % \n",
      "\n",
      "Averag validation accuracy for frost:  49.33 %,             Averag validation error for frost:  50.67 % \n",
      "======================================================================================\n",
      "Corruption: snow, Severity: 1\n",
      "Acc =: 30383./48960. ( 62.06 %),             Error =:  37.94 %\n",
      "Validation Acc =:  590./ 960. ( 61.46 %),             Validation Error =:  38.54 %\n",
      "Corruption: snow, Severity: 2\n",
      "Acc =: 23944./48960. ( 48.91 %),             Error =:  51.09 %\n",
      "Validation Acc =:  522./ 960. ( 54.38 %),             Validation Error =:  45.62 %\n",
      "Corruption: snow, Severity: 3\n",
      "Acc =: 24298./48960. ( 49.63 %),             Error =:  50.37 %\n",
      "Validation Acc =:  494./ 960. ( 51.46 %),             Validation Error =:  48.54 %\n",
      "Corruption: snow, Severity: 4\n",
      "Acc =: 20099./48960. ( 41.05 %),             Error =:  58.95 %\n",
      "Validation Acc =:  406./ 960. ( 42.29 %),             Validation Error =:  57.71 %\n",
      "Corruption: snow, Severity: 5\n",
      "Validation Acc =:  370./ 960. ( 38.54 %),             Validation Error =:  61.46 %\n",
      "Averag online accuracy for snow:  48.00 %,             Averag online error for snow:  52.00 % \n",
      "\n",
      "Averag validation accuracy for snow:  49.62 %,             Averag validation error for snow:  50.37 % \n",
      "======================================================================================\n",
      "Corruption: spatter, Severity: 1\n",
      "Acc =: 35664./48960. ( 72.84 %),             Error =:  27.16 %\n",
      "Validation Acc =:  715./ 960. ( 74.48 %),             Validation Error =:  25.52 %\n",
      "Corruption: spatter, Severity: 2\n",
      "Acc =: 32602./48960. ( 66.59 %),             Error =:  33.41 %\n",
      "Validation Acc =:  638./ 960. ( 66.46 %),             Validation Error =:  33.54 %\n",
      "Corruption: spatter, Severity: 3\n",
      "Acc =: 29545./48960. ( 60.35 %),             Error =:  39.65 %\n",
      "Validation Acc =:  588./ 960. ( 61.25 %),             Validation Error =:  38.75 %\n",
      "Corruption: spatter, Severity: 4\n",
      "Acc =: 26079./48960. ( 53.27 %),             Error =:  46.73 %\n",
      "Validation Acc =:  537./ 960. ( 55.94 %),             Validation Error =:  44.06 %\n",
      "Corruption: spatter, Severity: 5\n",
      "Acc =: 20998./48960. ( 42.89 %),             Error =:  57.11 %\n",
      "Validation Acc =:  433./ 960. ( 45.10 %),             Validation Error =:  54.90 %\n",
      "Averag online accuracy for spatter:  59.19 %,             Averag online error for spatter:  40.81 % \n",
      "\n",
      "Averag validation accuracy for spatter:  60.65 %,             Averag validation error for spatter:  39.35 % \n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00025\n",
    "bs = 64\n",
    "\n",
    "# ONLINE adaptation adaptation on the \"training set\"\n",
    "\n",
    "for corr in weather:\n",
    "    online_acc_sum = 0\n",
    "    validate_acc_sum = 0\n",
    "\n",
    "    for severity in range(1,6):\n",
    "        print(f\"Corruption: {corr}, Severity: {severity}\")\n",
    "        \n",
    "        # online adaptation:\n",
    "        adapted_model, accuracy = online_evaluate(imc_loaders, corr, severity, lr)\n",
    "        online_acc_sum += accuracy\n",
    "        \n",
    "        # offline validation:\n",
    "        val_acc = offline_validate(adapted_model, imc_loaders, corr, severity)\n",
    "        validate_acc_sum += val_acc\n",
    "        \n",
    "    print(f\"Averag online accuracy for {corr}: {100 * (online_acc_sum / 5): .2f} %, \\\n",
    "            Averag online error for {corr}: {100 * (1 - online_acc_sum / 5): .2f} % \")\n",
    "    print()\n",
    "    print(f\"Averag validation accuracy for {corr}: {100 * (validate_acc_sum / 5): .2f} %, \\\n",
    "            Averag validation error for {corr}: {100 * (1 - validate_acc_sum / 5): .2f} % \")\n",
    "    print(\"======================================================================================\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4643b270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corruption: snow, Severity: 1\n",
      "Acc =: 30466./48960. ( 62.23 %),             Error =:  37.77 %\n",
      "Validation Acc =:  589./ 960. ( 61.35 %),             Validation Error =:  38.65 %\n",
      "Corruption: snow, Severity: 2\n",
      "Acc =: 24128./48960. ( 49.28 %),             Error =:  50.72 %\n",
      "Validation Acc =:  519./ 960. ( 54.06 %),             Validation Error =:  45.94 %\n",
      "Corruption: snow, Severity: 3\n",
      "Acc =: 24433./48960. ( 49.90 %),             Error =:  50.10 %\n",
      "Validation Acc =:  500./ 960. ( 52.08 %),             Validation Error =:  47.92 %\n",
      "Corruption: snow, Severity: 4\n",
      "Acc =: 20096./48960. ( 41.05 %),             Error =:  58.95 %\n",
      "Validation Acc =:  406./ 960. ( 42.29 %),             Validation Error =:  57.71 %\n",
      "Corruption: snow, Severity: 5\n",
      "Acc =: 18757./48960. ( 38.31 %),             Error =:  61.69 %\n",
      "Validation Acc =:  384./ 960. ( 40.00 %),             Validation Error =:  60.00 %\n",
      "Averag online accuracy for snow:  48.15 %,             Averag online error for snow:  51.85 % \n",
      "\n",
      "Averag validation accuracy for snow:  49.96 %,             Averag validation error for snow:  50.04 % \n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "# a deleted cell of code, adaping on snow\n",
    "# I leave the result here for the sake of reference, for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d227054",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_us = ['fog', 'snow', 'spatter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "914fcc03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corruption: fog, Severity: 3\n",
      "Acc =: 30799./48960. ( 62.91 %),             Error =:  37.09 %\n",
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  632./ 960. ( 65.83 %),             Validation Error =:  34.17 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  465./ 960. ( 48.44 %),             Validation Error =:  51.56 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  568./ 960. ( 59.17 %),             Validation Error =:  40.83 %\n",
      "======================================================================================\n",
      "Corruption: snow, Severity: 3\n",
      "Acc =: 24380./48960. ( 49.80 %),             Error =:  50.20 %\n",
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  616./ 960. ( 64.17 %),             Validation Error =:  35.83 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  493./ 960. ( 51.35 %),             Validation Error =:  48.65 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  583./ 960. ( 60.73 %),             Validation Error =:  39.27 %\n",
      "======================================================================================\n",
      "Corruption: spatter, Severity: 3\n",
      "Acc =: 29558./48960. ( 60.37 %),             Error =:  39.63 %\n",
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  605./ 960. ( 63.02 %),             Validation Error =:  36.98 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  483./ 960. ( 50.31 %),             Validation Error =:  49.69 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  591./ 960. ( 61.56 %),             Validation Error =:  38.44 %\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "cross_valid_acc = {}\n",
    "\n",
    "for corr in weather_us:\n",
    "    online_acc_sum = 0\n",
    "    cross_valid_acc[corr] = {}\n",
    "    \n",
    "    for severity in [3]:\n",
    "        print(f\"Corruption: {corr}, Severity: {severity}\")\n",
    "\n",
    "        # online adaptation:\n",
    "        adapted_model, accuracy = online_evaluate(imc_loaders, corr, severity, lr)\n",
    "        online_acc_sum += accuracy\n",
    "        \n",
    "        # offline validation:\n",
    "        for val_corr in weather_us:\n",
    "            print(f\"cross-validating on corruption = {val_corr}\")\n",
    "            val_acc = offline_validate(adapted_model, imc_loaders, val_corr, severity)\n",
    "            cross_valid_acc[corr][val_corr] = val_acc\n",
    "\n",
    "#     print(f\"Averag online accuracy for {corr}: {100 * (online_acc_sum / 5): .2f} %, \\\n",
    "#             Averag online error for {corr}: {100 * (1 - online_acc_sum / 5): .2f} % \")\n",
    "#     print()\n",
    "#     print(f\"Averag validation accuracy for {corr}: {100 * (validate_acc_sum / 5): .2f} %, \\\n",
    "#             Averag validation error for {corr}: {100 * (1 - validate_acc_sum / 5): .2f} % \")\n",
    "    print(\"======================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1156ab23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  449./ 960. ( 46.77 %),             Validation Error =:  53.23 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  343./ 960. ( 35.73 %),             Validation Error =:  64.27 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  483./ 960. ( 50.31 %),             Validation Error =:  49.69 %\n"
     ]
    }
   ],
   "source": [
    "vanilla = models.resnet50(pretrained=True).to(device)\n",
    "for val_corr in weather_us:\n",
    "    print(f\"cross-validating on corruption = {val_corr}\")\n",
    "    val_acc = offline_validate(vanilla, imc_loaders, val_corr, severity, baseline=True)\n",
    "    cross_valid_acc[corr][val_corr] = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1310f129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
