{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7173890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "from torch.optim import SGD\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.utils.data as torchdata\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# from train_model import train_model\n",
    "# from test_model import test_model\n",
    "%matplotlib inline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84cbedf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d1710f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e0d7059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american-flag\n"
     ]
    }
   ],
   "source": [
    "filePath = '/local/rcs/ll3504/datasets/256_ObjectCategories/'\n",
    "namelist = os.listdir(filePath)\n",
    "nameDic_cal = {}\n",
    "for name in namelist:\n",
    "    splits = name.split(\".\")\n",
    "    nameDic_cal[int(splits[0])-1] = splits[1]\n",
    "print(nameDic_cal[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd26fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path='/database', dataset_name='caltech-256-common'):\n",
    "    # No holdout testing data. train and test data are the same, but different transformation\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    tr_dataset = datasets.ImageFolder(path + dataset_name + '/', data_transforms['train'])\n",
    "    te_dataset = datasets.ImageFolder(path + dataset_name + '/', data_transforms['test'])\n",
    "\n",
    "    return tr_dataset, te_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a8a1d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(train_dataset, test_dataset, valid_size=0.02, batch_size=128, train_size = 128):\n",
    "    '''\n",
    "    This function splits dataset into train, val, and test sets, and return train, val, test dataloaders.\n",
    "    Val and Test loaders are the same\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # what does the len function gives?\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    random.shuffle(indices)\n",
    "    train_idx, valid_idx = indices[split:split+train_size], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    \n",
    "\n",
    "\n",
    "    train_loader = torchdata.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=48, pin_memory=True, drop_last=False, sampler = train_sampler)\n",
    "    test_loader = torchdata.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=48, pin_memory=True, drop_last=False, sampler = valid_sampler)\n",
    "    dataloaders = {'train': train_loader,\n",
    "                   'val': test_loader,\n",
    "                   'test': test_loader}\n",
    "    dataset_sizes ={'train': train_size, #int(np.floor((1-valid_size) * num_train)),\n",
    "                    'val': int(np.floor(valid_size * num_train)),\n",
    "                    'test': int(np.floor(valid_size * num_train))}\n",
    "    return dataloaders, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d70b1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagebase = '/local/rcs/ll3504/datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53218aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corruption = ['fog', 'snow', 'spatter', 'gaussian_blur', 'gaussian_noise', 'brightness']\n",
    "weather = ['fog', 'snow', 'spatter', 'frost']\n",
    "digital = ['gaussian_noise', 'gaussian_blur', 'brightness', 'defocus_blur', 'contrast'] # NO gaussian noise in the files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca57975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imagenetc(imagebase, batch_size=128, sample_size = 128, corruption=corruption):\n",
    "    '''\n",
    "    Returns:\n",
    "        ref_dataloaders:          ImageNet original validation data, as a reference\n",
    "        ref_dataset_sizes:        1000, not the sizes of the real dataset in the ref_loader, probs used downstream\n",
    "        corrupted_dataloaders:    A list of corrupted dataloaders, each element in a list represetns the data loaders\n",
    "                                  for one corruption type. Each element contains ['train']['val']['test'] loaders\n",
    "        corrupted_dataset_sizes:  A list of dictionaries of the sizes of each loaders for each corruption\n",
    "        corruption:               A list of corruption names, in the same order of the corrupted_dataloaders\n",
    "    '''\n",
    "    corrupted_dataloaders = {}\n",
    "    \n",
    "    imagenet_val = datasets.ImageNet(imagebase+'imagenetc/', split='val', transform=transforms.Compose([\n",
    "            transforms.Resize([224, 224]),\n",
    "            transforms.CenterCrop((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "                                   target_transform=None)#, download=False)\n",
    "    \n",
    "    random_indices = random.sample(range(0, len(imagenet_val)), int(len(imagenet_val)*0.02))\n",
    "    imagenet_val_subset = data.Subset(imagenet_val, random_indices)\n",
    "    clean_val_loader = torch.utils.data.DataLoader(imagenet_val_subset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=48)\n",
    "    corrupted_dataloaders['clean'] = clean_val_loader\n",
    "#     ref_dataloaders = { 'val': val_loader,\n",
    "#                        'test': val_loader}\n",
    "#     ref_dataset_sizes ={'val': int(len(val_loader.dataset)),\n",
    "#                         'test': int(len(val_loader.dataset))}\n",
    "    \n",
    "    # for every type of corruption, go to the specified severity folder\n",
    "    for corr in corruption:\n",
    "        dataloader_all_sev = []\n",
    "\n",
    "        for severity in range(1,6):\n",
    "            \n",
    "            dataset_name = 'imagenetc/' + corr + '/' + str(severity)\n",
    "            # Get dataset from folder\n",
    "            corr_trian_images, corr_test_images = get_dataset(imagebase, dataset_name)\n",
    "\n",
    "            # Get corruption-specific train, val, test loader\n",
    "                # train: training data, non-overlap with val/test\n",
    "                # val: non-overlap with train, same as test\n",
    "                # test: non-overlap with train, same as test\n",
    "\n",
    "            corr_dataloaders, _ = split_dataset(corr_trian_images, corr_test_images, valid_size=0.02, batch_size=batch_size, train_size=sample_size)\n",
    "\n",
    "            dataloader_all_sev.append(corr_dataloaders)\n",
    "            corrupted_dataloaders[corr] = dataloader_all_sev\n",
    "        \n",
    "        \n",
    "#     return ref_dataloaders, ref_dataset_sizes, corrupted_dataloaders, corrupted_dataset_sizes, corruption\n",
    "    return clean_val_loader, corrupted_dataloaders\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a18b4fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f978eab5820>,\n",
       " {'clean': <torch.utils.data.dataloader.DataLoader at 0x7f978eab5820>,\n",
       "  'fog': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f9786b0fac0>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9786b0fb50>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9786b0fb50>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f9786b0ff40>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9786b0ffd0>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9786b0ffd0>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f97835c9400>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f97835c9490>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f97835c9490>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f97835c9880>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f97835c9910>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f97835c9910>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f97835c9d00>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f97835c9d90>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f97835c9d90>}],\n",
       "  'snow': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f976f4371c0>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f976f437250>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f976f437250>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f976f437640>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f976f4376d0>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f976f4376d0>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f976f437ac0>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f976f437b50>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f976f437b50>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f976f437f40>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f976f437fd0>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f976f437fd0>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f9765cb2400>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9765cb2490>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9765cb2490>}],\n",
       "  'spatter': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f9765cb2880>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9765cb2910>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9765cb2910>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f9765cb2d00>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9765cb2d90>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9765cb2d90>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f9761ad41c0>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9761ad4250>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9761ad4250>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f9761ad4640>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9761ad46d0>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9761ad46d0>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f9761ad4ac0>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9761ad4b50>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9761ad4b50>}],\n",
       "  'frost': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f9761ad4f40>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9761ad4fd0>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9761ad4fd0>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f975c350400>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f975c350490>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f975c350490>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f975c350880>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f975c350910>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f975c350910>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f975c350d00>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f975c350d90>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f975c350d90>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f97581f21c0>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f97581f2250>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f97581f2250>}],\n",
       "  'gaussian_noise': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f97581f2640>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f97581f26d0>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f97581f26d0>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f97581f2ac0>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f97581f2b50>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f97581f2b50>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f97581f2f40>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f97581f2fd0>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f97581f2fd0>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f9752a6d400>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9752a6d490>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9752a6d490>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f9752a6d880>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9752a6d910>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9752a6d910>}],\n",
       "  'gaussian_blur': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f9752a6dd00>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9752a6dd90>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9752a6dd90>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f974e88f1c0>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f974e88f250>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f974e88f250>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f974e88f640>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f974e88f6d0>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f974e88f6d0>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f974e88fac0>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f974e88fb50>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f974e88fb50>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f974e88ff40>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f974e88ffd0>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f974e88ffd0>}],\n",
       "  'brightness': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f974910a400>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f974910a490>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f974910a490>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f974910a880>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f974910a910>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f974910a910>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f974910ad00>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f974910ad90>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f974910ad90>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f9744fac1c0>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9744fac250>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9744fac250>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f9744fac640>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9744fac6d0>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9744fac6d0>}],\n",
       "  'defocus_blur': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f9744facac0>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9744facb50>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9744facb50>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f9744facf40>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9744facfd0>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9744facfd0>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f973f827400>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f973f827490>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f973f827490>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f973f827880>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f973f827910>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f973f827910>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f973f827d00>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f973f827d90>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f973f827d90>}],\n",
       "  'contrast': [{'train': <torch.utils.data.dataloader.DataLoader at 0x7f973b6491c0>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f973b649250>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f973b649250>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f973b649640>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f973b6496d0>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f973b6496d0>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f973b649ac0>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f973b649b50>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f973b649b50>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f973b649f40>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f973b649fd0>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f973b649fd0>},\n",
       "   {'train': <torch.utils.data.dataloader.DataLoader at 0x7f9735ec3400>,\n",
       "    'val': <torch.utils.data.dataloader.DataLoader at 0x7f9735ec3490>,\n",
       "    'test': <torch.utils.data.dataloader.DataLoader at 0x7f9735ec3490>}]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_loader, imc_loaders = get_imagenetc(imagebase, batch_size=64, sample_size = 49000, corruption=(weather+digital))\n",
    "clean_loader, imc_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce0234d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imagenet(imagebase, batch_size=128, sample_size = 128):\n",
    "    # this is the imageNet validation data\n",
    "    imagenet_val = datasets.ImageNet(imagebase+'imagenetc/', split='val', transform=transforms.Compose([\n",
    "            transforms.Resize([224, 224]),\n",
    "            transforms.CenterCrop((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "                                   target_transform=None)#, download=False)\n",
    "    \n",
    "    # TODO: subsample some size of ImageNet training data as source\n",
    "        # Doesn't need this step\n",
    "#     print(\"DEBUGGING: imagenet_val size is:\", len(imagenet_val))\n",
    "    \n",
    "    random_indices = random.sample(range(0, len(imagenet_val)), int(len(imagenet_val)*0.02))\n",
    "#     print(\"DEBUGGING: random indices are:\", len(random_indices))\n",
    "    imagenet_val_subset = data.Subset(imagenet_val, random_indices)\n",
    "    val_loader = torch.utils.data.DataLoader(imagenet_val_subset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=48)\n",
    "    ref_dataloaders = { 'val': val_loader,\n",
    "                       'test': val_loader}\n",
    "    ref_dataset_sizes ={'val': int(len(val_loader.dataset)),\n",
    "                        'test': int(len(val_loader.dataset))}\n",
    "    \n",
    "    return ref_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5edb380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_evaluate(corrupt_loaders, corrutpion, severity, lr):\n",
    "    start = time.time()\n",
    "    resnet50 = models.resnet50(pretrained=True)\n",
    "    resnet50 = tent.configure_model(resnet50)\n",
    "    params, param_names = tent.collect_params(resnet50)\n",
    "    optimizer = SGD(params, lr=lr)\n",
    "    tented_resnet50 = tent.Tent(resnet50, optimizer).to(device)\n",
    "\n",
    "    num_correct, num_samples = 0., 0.\n",
    "    \n",
    "    trainloader = corrupt_loaders[corrutpion][severity-1]['train']\n",
    "\n",
    "    for images, targets in trainloader:\n",
    "        logits = tented_resnet50(images.to(device))\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        num_correct += (predictions.detach().cpu() == targets).float().sum()\n",
    "        num_samples += len(targets)\n",
    "\n",
    "    adapt_time = time.time() - start\n",
    "    accuracy = num_correct / num_samples\n",
    "    print(f\"Acc =: {num_correct:#5.0f}/{num_samples:#5.0f} ({100 * accuracy: .2f} %), \\\n",
    "            Error =: {100 * (1 - accuracy): .2f} %\")\n",
    "    print(f\"Adaptation time for one epoch on {num_samples} images takes {adapt_time}s\")\n",
    "    return tented_resnet50, accuracy, adapt_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e040b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_validate(model, corrupt_loaders, corruption, severity, baseline=False, clean_data=False, bn_adapt=False):\n",
    "    if baseline:\n",
    "        if not bn_adapt:\n",
    "            model.eval()\n",
    "        else:\n",
    "            model.train() # TODO: this is a very sloppy way of doing it, change it\n",
    "    else:\n",
    "        if not bn_adapt: # If we don't adapt the BN statistics at validation time, set to eval mode.\n",
    "            model.model.eval() \n",
    "        model.offline_validation()\n",
    "        \n",
    "    if clean_data:\n",
    "        valloader = corrupt_loaders['clean']\n",
    "    else:\n",
    "        valloader = corrupt_loaders[corruption][severity-1]['val']\n",
    "    \n",
    "    num_correct, num_samples = 0., 0.\n",
    "\n",
    "#     with model.no_grad():\n",
    "    for images, targets in valloader:\n",
    "        logits = model(images.to(device))\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        num_correct += (predictions.detach().cpu() == targets).float().sum()\n",
    "        num_samples += len(targets)\n",
    "\n",
    "    accuracy = num_correct / num_samples\n",
    "    print(f\"Validation Acc =: {num_correct:#5.0f}/{num_samples:#5.0f} ({100 * accuracy: .2f} %), \\\n",
    "            Validation Error =: {100 * (1 - accuracy): .2f} %\")\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4438e40",
   "metadata": {},
   "source": [
    "# Replicating TENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23dafc53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corruption: gaussian_noise, Severity: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7f99a5baa5e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zw2774/bin/anaconda3/lib/python3.9/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 15231, 15279, 15327, 15375, 15423, 15471, 15522, 15570, 15625, 15697, 15746, 15794, 15843, 15891, 15948, 15997, 16057, 16105, 16153, 16201, 16249, 16301, 16372, 16420, 16468, 16516, 16564, 16613, 16661, 16709, 16757, 16805, 16853, 16901, 16949, 16997, 17045, 17093, 17141, 17190, 17241, 17289, 17337) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.9/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15129/4062387298.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# online adaptation:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0madapted_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monline_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimc_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseverity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0madapt_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0monline_acc_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15129/2842836297.py\u001b[0m in \u001b[0;36monline_evaluate\u001b[0;34m(corrupt_loaders, corrutpion, severity, lr)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrupt_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorrutpion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseverity\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtented_resnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 15231, 15279, 15327, 15375, 15423, 15471, 15522, 15570, 15625, 15697, 15746, 15794, 15843, 15891, 15948, 15997, 16057, 16105, 16153, 16201, 16249, 16301, 16372, 16420, 16468, 16516, 16564, 16613, 16661, 16709, 16757, 16805, 16853, 16901, 16949, 16997, 17045, 17093, 17141, 17190, 17241, 17289, 17337) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "lr = 0.00025\n",
    "bs = 64\n",
    "\n",
    "# ONLINE adaptation adaptation on the \"training set\"\n",
    "\n",
    "for corr in digital:\n",
    "    online_acc_sum = 0\n",
    "    validate_acc_sum = 0\n",
    "\n",
    "    for severity in range(1,6):\n",
    "        print(f\"Corruption: {corr}, Severity: {severity}\")\n",
    "        \n",
    "        # online adaptation:\n",
    "        start = time.time()\n",
    "        adapted_model, accuracy, _ = online_evaluate(imc_loaders, corr, severity, lr)\n",
    "        adapt_time = time.time() - start\n",
    "        online_acc_sum += accuracy\n",
    "        \n",
    "        # offline validation:\n",
    "        val_acc = offline_validate(adapted_model, imc_loaders, corr, severity)\n",
    "        validate_acc_sum += val_acc\n",
    "        \n",
    "    print(f\"Averag online accuracy for {corr}: {100 * (online_acc_sum / 5): .2f} %, \\\n",
    "            Averag online error for {corr}: {100 * (1 - online_acc_sum / 5): .2f} % \")\n",
    "    print()\n",
    "    print(f\"Averag validation accuracy for {corr}: {100 * (validate_acc_sum / 5): .2f} %, \\\n",
    "            Averag validation error for {corr}: {100 * (1 - validate_acc_sum / 5): .2f} % \")\n",
    "    print(\"======================================================================================\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4722e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a deleted cell of code, adaping on snow\n",
    "# I leave the result here for the sake of reference, for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c976ea3e",
   "metadata": {},
   "source": [
    "# 7x7 Table - adapt + cross validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "737174ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fog', 'snow', 'spatter', 'gaussian_noise', 'gaussian_blur', 'brightness']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_us = ['fog', 'snow', 'spatter']\n",
    "digital_us = ['gaussian_noise', 'gaussian_blur', 'brightness']\n",
    "weather_us + digital_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cbb255d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corruption: fog, Severity: 3\n",
      "Acc =: 30823./49000. ( 62.90 %),             Error =:  37.10 %\n",
      "Adaptation time for one epoch on 49000.0 images takes 133.26694416999817s\n",
      "cross-validating on clean data\n",
      "Validation Acc =:  741./1000. ( 74.10 %),             Validation Error =:  25.90 %\n",
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  644./1000. ( 64.40 %),             Validation Error =:  35.60 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  494./1000. ( 49.40 %),             Validation Error =:  50.60 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  578./1000. ( 57.80 %),             Validation Error =:  42.20 %\n",
      "cross-validating on corruption = gaussian_noise\n",
      "Validation Acc =:  472./1000. ( 47.20 %),             Validation Error =:  52.80 %\n",
      "cross-validating on corruption = gaussian_blur\n",
      "Validation Acc =:  456./1000. ( 45.60 %),             Validation Error =:  54.40 %\n",
      "cross-validating on corruption = brightness\n",
      "Validation Acc =:  737./1000. ( 73.70 %),             Validation Error =:  26.30 %\n",
      "======================================================================================\n",
      "Corruption: snow, Severity: 3\n",
      "Acc =: 24500./49000. ( 50.00 %),             Error =:  50.00 %\n",
      "Adaptation time for one epoch on 49000.0 images takes 134.59779047966003s\n",
      "cross-validating on clean data\n",
      "Validation Acc =:  732./1000. ( 73.20 %),             Validation Error =:  26.80 %\n",
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  630./1000. ( 63.00 %),             Validation Error =:  37.00 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  533./1000. ( 53.30 %),             Validation Error =:  46.70 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  602./1000. ( 60.20 %),             Validation Error =:  39.80 %\n",
      "cross-validating on corruption = gaussian_noise\n",
      "Validation Acc =:  474./1000. ( 47.40 %),             Validation Error =:  52.60 %\n",
      "cross-validating on corruption = gaussian_blur\n",
      "Validation Acc =:  427./1000. ( 42.70 %),             Validation Error =:  57.30 %\n",
      "cross-validating on corruption = brightness\n",
      "Validation Acc =:  737./1000. ( 73.70 %),             Validation Error =:  26.30 %\n",
      "======================================================================================\n",
      "Corruption: spatter, Severity: 3\n",
      "Acc =: 29538./49000. ( 60.28 %),             Error =:  39.72 %\n",
      "Adaptation time for one epoch on 49000.0 images takes 133.68848061561584s\n",
      "cross-validating on clean data\n",
      "Validation Acc =:  749./1000. ( 74.90 %),             Validation Error =:  25.10 %\n",
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  627./1000. ( 62.70 %),             Validation Error =:  37.30 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  512./1000. ( 51.20 %),             Validation Error =:  48.80 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  599./1000. ( 59.90 %),             Validation Error =:  40.10 %\n",
      "cross-validating on corruption = gaussian_noise\n",
      "Validation Acc =:  496./1000. ( 49.60 %),             Validation Error =:  50.40 %\n",
      "cross-validating on corruption = gaussian_blur\n",
      "Validation Acc =:  446./1000. ( 44.60 %),             Validation Error =:  55.40 %\n",
      "cross-validating on corruption = brightness\n",
      "Validation Acc =:  745./1000. ( 74.50 %),             Validation Error =:  25.50 %\n",
      "======================================================================================\n",
      "Corruption: gaussian_noise, Severity: 3\n",
      "Acc =: 23642./49000. ( 48.25 %),             Error =:  51.75 %\n",
      "Adaptation time for one epoch on 49000.0 images takes 133.28312301635742s\n",
      "cross-validating on clean data\n",
      "Validation Acc =:  748./1000. ( 74.80 %),             Validation Error =:  25.20 %\n",
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  617./1000. ( 61.70 %),             Validation Error =:  38.30 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  496./1000. ( 49.60 %),             Validation Error =:  50.40 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  587./1000. ( 58.70 %),             Validation Error =:  41.30 %\n",
      "cross-validating on corruption = gaussian_noise\n",
      "Validation Acc =:  513./1000. ( 51.30 %),             Validation Error =:  48.70 %\n",
      "cross-validating on corruption = gaussian_blur\n",
      "Validation Acc =:  466./1000. ( 46.60 %),             Validation Error =:  53.40 %\n",
      "cross-validating on corruption = brightness\n",
      "Validation Acc =:  734./1000. ( 73.40 %),             Validation Error =:  26.60 %\n",
      "======================================================================================\n",
      "Corruption: gaussian_blur, Severity: 3\n",
      "Acc =: 22452./49000. ( 45.82 %),             Error =:  54.18 %\n",
      "Adaptation time for one epoch on 49000.0 images takes 134.01890993118286s\n",
      "cross-validating on clean data\n",
      "Validation Acc =:  739./1000. ( 73.90 %),             Validation Error =:  26.10 %\n",
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  631./1000. ( 63.10 %),             Validation Error =:  36.90 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  490./1000. ( 49.00 %),             Validation Error =:  51.00 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  596./1000. ( 59.60 %),             Validation Error =:  40.40 %\n",
      "cross-validating on corruption = gaussian_noise\n",
      "Validation Acc =:  482./1000. ( 48.20 %),             Validation Error =:  51.80 %\n",
      "cross-validating on corruption = gaussian_blur\n",
      "Validation Acc =:  510./1000. ( 51.00 %),             Validation Error =:  49.00 %\n",
      "cross-validating on corruption = brightness\n",
      "Validation Acc =:  744./1000. ( 74.40 %),             Validation Error =:  25.60 %\n",
      "======================================================================================\n",
      "Corruption: brightness, Severity: 3\n",
      "Acc =: 35022./49000. ( 71.47 %),             Error =:  28.53 %\n",
      "Adaptation time for one epoch on 49000.0 images takes 134.7716236114502s\n",
      "cross-validating on clean data\n",
      "Validation Acc =:  742./1000. ( 74.20 %),             Validation Error =:  25.80 %\n",
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  629./1000. ( 62.90 %),             Validation Error =:  37.10 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  480./1000. ( 48.00 %),             Validation Error =:  52.00 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  574./1000. ( 57.40 %),             Validation Error =:  42.60 %\n",
      "cross-validating on corruption = gaussian_noise\n",
      "Validation Acc =:  460./1000. ( 46.00 %),             Validation Error =:  54.00 %\n",
      "cross-validating on corruption = gaussian_blur\n",
      "Validation Acc =:  434./1000. ( 43.40 %),             Validation Error =:  56.60 %\n",
      "cross-validating on corruption = brightness\n",
      "Validation Acc =:  737./1000. ( 73.70 %),             Validation Error =:  26.30 %\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "cross_valid_acc = {}\n",
    "\n",
    "for corr in weather_us + digital_us:\n",
    "    online_acc_sum = 0\n",
    "    cross_valid_acc[corr] = {}\n",
    "    \n",
    "    for severity in [3]:\n",
    "        print(f\"Corruption: {corr}, Severity: {severity}\")\n",
    "\n",
    "        # online adaptation:\n",
    "        adapted_model, accuracy, _ = online_evaluate(imc_loaders, corr, severity, lr)\n",
    "        online_acc_sum += accuracy\n",
    "        \n",
    "        # offline validation on clean set\n",
    "        print(f\"cross-validating on clean data\")\n",
    "        val_acc = offline_validate(adapted_model, imc_loaders, corruption=None, severity=None, clean_data=True)\n",
    "        cross_valid_acc[corr]['clean'] = val_acc        \n",
    "        \n",
    "        # offline validation:\n",
    "        for val_corr in weather_us + digital_us:\n",
    "            print(f\"cross-validating on corruption = {val_corr}\")\n",
    "            val_acc = offline_validate(adapted_model, imc_loaders, val_corr, severity)\n",
    "            cross_valid_acc[corr][val_corr] = val_acc\n",
    "\n",
    "#     print(f\"Averag online accuracy for {corr}: {100 * (online_acc_sum / 5): .2f} %, \\\n",
    "#             Averag online error for {corr}: {100 * (1 - online_acc_sum / 5): .2f} % \")\n",
    "#     print()\n",
    "#     print(f\"Averag validation accuracy for {corr}: {100 * (validate_acc_sum / 5): .2f} %, \\\n",
    "#             Averag validation error for {corr}: {100 * (1 - validate_acc_sum / 5): .2f} % \")\n",
    "    print(\"======================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1afde225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch BN adaptation at test time:\n",
      "Validation Acc =:  739./1000. ( 73.90 %),             Validation Error =:  26.10 %\n",
      "cross-validating on clean data\n",
      "Validation Acc =:  753./1000. ( 75.30 %),             Validation Error =:  24.70 %\n",
      "cross-validating on corruption = fog\n",
      "Validation Acc =:  381./1000. ( 38.10 %),             Validation Error =:  61.90 %\n",
      "cross-validating on corruption = snow\n",
      "Validation Acc =:  348./1000. ( 34.80 %),             Validation Error =:  65.20 %\n",
      "cross-validating on corruption = spatter\n",
      "Validation Acc =:  482./1000. ( 48.20 %),             Validation Error =:  51.80 %\n",
      "cross-validating on corruption = gaussian_noise\n",
      "Validation Acc =:  259./1000. ( 25.90 %),             Validation Error =:  74.10 %\n",
      "cross-validating on corruption = gaussian_blur\n",
      "Validation Acc =:  368./1000. ( 36.80 %),             Validation Error =:  63.20 %\n",
      "cross-validating on corruption = brightness\n",
      "Validation Acc =:  715./1000. ( 71.50 %),             Validation Error =:  28.50 %\n"
     ]
    }
   ],
   "source": [
    "severity = 3\n",
    "baseline_valid_acc = {}\n",
    "\n",
    "vanilla = models.resnet50(pretrained=True).to(device)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"cross-validating on clean data\")\n",
    "val_acc = offline_validate(vanilla, imc_loaders, corruption=None, severity=None, clean_data=True, baseline=True)\n",
    "baseline_valid_acc['clean'] = val_acc\n",
    "\n",
    "for val_corr in weather_us + digital_us:\n",
    "    print(f\"cross-validating on corruption = {val_corr}\")\n",
    "    val_acc = offline_validate(vanilla, imc_loaders, val_corr, severity, baseline=True)\n",
    "    baseline_valid_acc[val_corr] = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0107b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch BN adaptation at test time:\n",
      "Validation Acc =:  743./1000. ( 74.30 %),             Validation Error =:  25.70 %\n",
      "Batch BN adaptation on corruption = fog\n",
      "Validation Acc =:  618./1000. ( 61.80 %),             Validation Error =:  38.20 %\n",
      "Batch BN adaptation on corruption = snow\n",
      "Validation Acc =:  478./1000. ( 47.80 %),             Validation Error =:  52.20 %\n",
      "Batch BN adaptation on corruption = spatter\n",
      "Validation Acc =:  566./1000. ( 56.60 %),             Validation Error =:  43.40 %\n",
      "Batch BN adaptation on corruption = gaussian_noise\n",
      "Validation Acc =:  455./1000. ( 45.50 %),             Validation Error =:  54.50 %\n",
      "Batch BN adaptation on corruption = gaussian_blur\n",
      "Validation Acc =:  430./1000. ( 43.00 %),             Validation Error =:  57.00 %\n",
      "Batch BN adaptation on corruption = brightness\n",
      "Validation Acc =:  738./1000. ( 73.80 %),             Validation Error =:  26.20 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Batch BN adaptation at test time:')\n",
    "bn_adapt_val_acc = offline_validate(vanilla, imc_loaders, corruption=None, severity=None, clean_data=True, baseline=True, bn_adapt=True)\n",
    "baseline_valid_acc['BN_adapt'] = bn_adapt_val_acc\n",
    "\n",
    "for val_corr in weather_us + digital_us:\n",
    "    print(f\"Batch BN adaptation on corruption = {val_corr}\")\n",
    "    val_acc = offline_validate(vanilla, imc_loaders, val_corr, severity, baseline=True, bn_adapt=True)\n",
    "    baseline_valid_acc[val_corr] = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8c3fbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vanilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f50e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
